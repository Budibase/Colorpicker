'use strict';

function _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }

var EventEmitter = require('events');
var fs = require('fs');
var fs__default = _interopDefault(fs);
var util = require('util');
var path = require('path');

const readdir = util.promisify(fs.readdir);
const stat = util.promisify(fs.stat);
class CheapWatch extends EventEmitter {
    constructor(data) {
        super();
        this.watch = true;
        this.debounce = 10;
        this.paths = new Map();
        this._watchers = new Map();
        this._timeouts = new Map();
        this._queue = [];
        this._status = 0;
        Object.assign(this, data);
        if (typeof this.dir !== 'string') {
            throw new TypeError('dir must be a string');
        }
        if (this.filter && typeof this.filter !== 'function') {
            throw new TypeError('filter must be a function');
        }
        if (typeof this.watch !== 'boolean') {
            throw new TypeError('watch must be a boolean');
        }
        if (typeof this.debounce !== 'number') {
            throw new TypeError('debounce must be a number');
        }
    }
    async init() {
        if (this._status !== 0) {
            throw new Error('cannot call init() twice');
        }
        this._status = 1;
        await this._recurse(this.dir);
        this._status = 2;
    }
    close() {
        if (this._status === 0 || this._status === 1) {
            throw new Error('cannot call close() before init() finishes');
        }
        if (this._status === 4) {
            throw new Error('cannot call close() twice');
        }
        this._status = 4;
        for (const watcher of this._watchers.values()) {
            watcher.close();
        }
    }
    async _recurse(full) {
        const path = full.slice(this.dir.length + 1);
        const stats = await stat(full);
        if (path) {
            if (this.filter && !(await this.filter({ path, stats }))) {
                return;
            }
            this.paths.set(path, stats);
        }
        if (stats.isDirectory()) {
            if (this.watch) {
                this._watchers.set(path, fs.watch(full, this._handle.bind(this, full)).on('error', () => { }));
            }
            await Promise.all((await readdir(full)).map(sub => this._recurse(full + '/' + sub)));
        }
    }
    _handle(dir, event, file) {
        this._debounce(dir);
        this._debounce(dir + '/' + file);
    }
    _debounce(path) {
        if (this._timeouts.has(path)) {
            clearTimeout(this._timeouts.get(path));
        }
        this._timeouts.set(path, setTimeout(() => {
            this._timeouts.delete(path);
            this._enqueue(path);
        }, this.debounce));
    }
    async _enqueue(full) {
        this._queue.push(full);
        if (this._status !== 2) {
            return;
        }
        this._status = 3;
        while (this._queue.length) {
            const full = this._queue.shift();
            const path = full.slice(this.dir.length + 1);
            const stats = await stat(full).catch(() => { });
            if (stats) {
                if (this.filter && !(await this.filter({ path, stats }))) {
                    continue;
                }
                const isNew = !this.paths.has(path);
                this.paths.set(path, stats);
                if (path) {
                    this.emit('+', { path, stats, isNew });
                }
                if (stats.isDirectory() && !this._watchers.has(path)) {
                    await this._recurse(full);
                    for (const [new_path, stats] of this.paths.entries()) {
                        if (new_path.startsWith(path + '/')) {
                            this.emit('+', { path: new_path, stats, isNew: true });
                        }
                    }
                }
            }
            else if (this.paths.has(path)) {
                const stats = this.paths.get(path);
                this.paths.delete(path);
                this.emit('-', { path, stats });
                if (this._watchers.has(path)) {
                    for (const old_path of this._watchers.keys()) {
                        if (old_path === path || old_path.startsWith(path + '/')) {
                            this._watchers.get(old_path).close();
                            this._watchers.delete(old_path);
                        }
                    }
                    for (const old_path of this.paths.keys()) {
                        if (old_path.startsWith(path + '/')) {
                            const stats = this.paths.get(old_path);
                            this.paths.delete(old_path);
                            this.emit('-', { path: old_path, stats });
                        }
                    }
                }
            }
        }
        this._status = 2;
    }
}

const map = (mapper, o) => {
  const fn = x => {
    if (x.map) return x.map(mapper)
    const result = [];
    let i = 0;
    for (const item of x) {
      result.push(mapper(item, i++, x));
    }
    return result
  };
  if (o) return fn(o)
  return o
};

var reader = (
  { log, dir, extensions, watch: _watch = false, ignore },
  build
) => {
  const isWatchedFile = path => extensions.some(x => path.endsWith(x));

  const filter = ({ path, stats }) =>
    (stats.isDirectory() || isWatchedFile(path)) && !(ignore && ignore(path));

  let watcher;

  const start = ({ watch = _watch } = {}) => {
    watcher = new CheapWatch({ dir, watch, filter });

    log.info(
      '%s %s*/**/*.(%s)',
      watch ? 'Watching' : 'Reading',
      dir,
      extensions.map(x => x.slice(1)).join('|')
    );

    if (watch) {
      watcher.on('+', ({ path, stats, isNew }) => {
        if (isNew) {
          build.add([path, stats]);
        } else {
          build.update([path, stats]);
        }
      });

      watcher.on('-', ({ path, stats }) => build.remove([path, stats]));
    }

    return watcher
      .init()
      .then(() => map(build.add, watcher.paths))
      .then(build.start)
  };

  let initPromise;

  const init = (...args) => initPromise || (initPromise = start(...args));

  const close = async () => {
    await initPromise;
    watcher.close();
  };

  return { init, close, isWatchedFile }
};

const identity = x => x;

const noop = () => {};

const Deferred = () => {
  let resolve, reject;
  const promise = new Promise((_resolve, _reject) => {
    resolve = _resolve;
    reject = _reject;
  });
  return { promise, resolve, reject }
};

const stringHashCode = str => {
  let hash = 5381;
  let i = str.length;
  while (i--) hash = ((hash << 5) - hash) ^ str.charCodeAt(i);
  return (hash >>> 0).toString(36)
};

const parseItem = ({ dir, extensions }, arg) => {
  if (Array.isArray(arg)) {
    const [relative] = arg;
    const ext =
      extensions.find(x => relative.endsWith(x)) || path.extname(relative);
    return {
      isFile: true,
      relative,
      absolute: path.join(dir, relative),
      extension: ext,
      path: ext ? relative.slice(0, -ext.length) : relative,
    }
  }
  return arg
};

const parseFile = options => async (arg, previous) => {
  const { leadingSlash, parse = identity } = options;

  const item = parseItem(options, arg);

  item.id = stringHashCode(item.isFile ? item.absolute : `d:${item.path}`);

  if (leadingSlash && item.path[0] !== '/') {
    item.path = '/' + item.path;
  }

  const result = await parse(item, previous, options);

  // canceled
  if (result === false) return false

  return item
};

const _ = JSON.stringify;

const indent = (...args) => {
  if (args.length === 2) {
    return (_lines, collapse) => indent(...args, _lines, collapse)
  }
  const [n, glue, _lines, collapse] = args;
  const lines = _lines.filter(Boolean);
  const spaces = '  '.repeat(n);
  return collapse && lines.length === 2
    ? spaces + lines.join('')
    : lines.map(x => (/^\s/.test(x) ? x : spaces + x)).join(glue + '\n')
};

indent.collapse = (...args) => indent(...args, true);

const _ref = x => `${x.isFile ? 'f' : 'd'}[${x.i}]`;

const _props = (props = {}) =>
  Object.entries(props).map(([prop, value]) => `${_(prop)}: ${_(value)}`);

const FILE = Symbol('routix.tree.FILE');

const isFileNode = node => node[FILE] && node[FILE].isFile;

const notExcludedFromTree = ([, node]) =>
  !node[FILE] || node[FILE].tree !== false;

const getNode = (from, steps) => {
  let node = from;
  for (const step of steps) {
    if (step === '') continue
    if (!node[step]) {
      node[step] = {};
    }
    node = node[step];
  }
  return node
};

const getNodes = (from, steps) => {
  const nodes = [from];
  let cursor = from;
  for (const step of steps) {
    if (step === '') continue
    if (!cursor[step]) {
      cursor[step] = {};
    }
    cursor = cursor[step];
    nodes.push(cursor);
  }
  return nodes
};

const _tree = (format, rootPath, root) =>
  indent(0, '', [
    `const tree = {`,
    indent(1, ',', [
      `path: ${JSON.stringify(rootPath)}`,
      `isRoot: true`,
      ..._props(format(root)),
      root.children.length
        ? indent(1, '', [
            'children: [',
            indent(2, ',', root.children.map(_ref)),
            ']',
          ])
        : 'children: []',
    ]),
    '}',
  ]);

var Tree = (options, { parse, build }) => {
  const {
    leadingSlash,
    format = noop,
    cacheChildren = true,
    sortChildren = false,
    resolveConflict,
  } = options;

  const rootPath = leadingSlash ? '/' : '';

  const root = {
    [FILE]: { isRoot: true, path: rootPath },
  };

  const emitDirs = (children, dirs) => {
    children.forEach(file => {
      emitDirs(file.children, dirs);
      if (!file.isFile && !file.isRoot) {
        dirs.push(file);
      }
    });
  };

  const unfold = async (node, _path, dirs) => {
    // --- create directory node (if needed) ---

    if (!node[FILE]) {
      const p = _path.slice(0, -1);
      const file = {
        isFile: false,
        path: p,
      };
      await parse(file, null, options);
      node[FILE] = file;
    }

    const file = node[FILE];

    // --- create children prop (if not cached) ---

    if (!cacheChildren || !file.children) {
      const children = Object.entries(node).filter(notExcludedFromTree);

      await Promise.all(
        children.map(([seg, x]) => unfold(x, _path + seg + '/', dirs))
      );

      file.children = children.map(([, x]) => x[FILE]);

      if (sortChildren) {
        file.children.sort(sortChildren);
      }
    } else {
      emitDirs(file.children, dirs);
    }

    if (!file.isFile && !file.isRoot) {
      dirs.push(file);
    }
  };

  const split = leadingSlash ? x => x.slice(1).split('/') : x => x.split('/');

  const splitPath = file => split(file.path);

  const invalidate = file => {
    const steps = splitPath(file);
    const nodes = getNodes(root, steps);
    for (const node of nodes) {
      if (node[FILE]) delete node[FILE].children;
    }
  };

  const isConflict = (file, existing, replace) => {
    if (!existing) return false
    if (!replace) return true
    // NOTE if it's not the same file, then it's a conflict, even with replace
    //
    // With:
    // - foo.js       => path: /foo
    // - foo.index.js => path: /foo
    //
    // When I edit foo.index.js, I will have update with replace at /foo, but
    // really it is a conflict because in a full build foo.index.js would have
    // met foo.js. So it needs resolution.
    //
    return file.absolute !== existing.absolute
  };

  const put = (file, replace) => {
    const steps = splitPath(file);
    const node = getNode(root, steps);
    if (node[FILE]) {
      if (node[FILE].isRoot) {
        root[FILE] = Object.assign(file, root[FILE]);
      } else {
        if (isConflict(file, node[FILE], replace)) {
          // if (!replace && node[FILE].isFile) {
          if (!file.isFile) return
          const existing = node[FILE];
          const newFile = { ...file };
          const newExisting = { ...existing };
          if (resolveConflict && resolveConflict(newFile, newExisting)) {
            build.remove(existing);
            build.remove(file); // ensure other builders don't keep a stale copy
            build.add(newExisting);
            build.add(newFile);
            return
          }
          throw new Error(`File node conflict: ${file.path}`)
        }
      }
    }
    node[FILE] = file;
  };

  const add = file => {
    if (cacheChildren) invalidate(file);
    put(file, false);
  };

  const update = (file, previous) => {
    if (cacheChildren) {
      remove(previous);
      invalidate(file);
    }
    put(file, true);
  };

  const remove = file => {
    if (cacheChildren) invalidate(file);
    const steps = splitPath(file);
    const nodes = getNodes(root, steps);
    const target = nodes[nodes.length - 1];
    delete target[FILE];
    let i = nodes.length;
    while (i--) {
      const node = nodes[i];
      delete node[steps[i]];
      if (isFileNode(node)) break
      if (Object.keys(node).length > 0) break
    }
  };

  const prepare = async () => {
    const dirs = [];
    await unfold(root, rootPath, dirs);
    return dirs
  };

  const generate = () => _tree(format, rootPath, root[FILE]);

  return {
    add,
    update,
    remove,

    prepare,
    generate,
  }
};

const notEmpty = x => !x.isEmpty;

const _$1 = JSON.stringify;

const _props$1 = (props = {}) =>
  // Object.entries(props).map(([prop, value]) => `${_(prop)}: ${_(value)}`)
  Object.entries(props).flatMap(([prop, value]) => {
    const json = JSON.stringify(value, false, 2) || 'undefined';
    const lines = json.split('\n');
    const first = lines.shift();
    return [`${_$1(prop)}: ${first}`, ...lines.map(x => '    ' + x)].join('\n')
  });

const _children = children =>
  // NOTE children not here when tree:false
  children && `children: () => [${children.map(_ref).join(', ')}]`;

const _file = (
  props,
  { id: withId, importDefault, importProp, resolve },
  { i, id, absolute, path, children }
) =>
  indent(1, '', [
    `{ // f[${i}]`,
    indent(2, ',', [
      withId && `id: ${_$1(id)}`,
      `path: ${_$1(path)}`,
      `${importProp}: () => import(${_$1(
        resolve ? resolve(absolute) : absolute
      )})${importDefault ? '.then(dft)' : ''}`,
      ..._props$1(props),
      children && children.length > 0 && _children(children),
    ]),
    '}',
  ]);

const _dir = (props, { id: withId }, { i, id, path, children }) =>
  indent(1, '', [
    `{ // d[${i}]`,
    indent(2, ',', [
      withId && `id: ${_$1(id)}`,
      `path: ${_$1(path)}`,
      ..._props$1(props),
      _children(children),
    ]),
    '}',
  ]);

const _generate = (
  { id, format, importDefault, importProp, resolve },
  files,
  dirs
) =>
  indent(0, '\n', [
    importDefault && `const dft = m => m.default`,

    indent.collapse(0, '', [
      'const f /* files */ = [',
      indent(
        1,
        ','
      )(
        files.map(x =>
          _file(format(x), { id, importDefault, importProp, resolve }, x)
        )
      ),
      ']',
    ]),

    dirs &&
      indent.collapse(0, '', [
        'const d /* dirs */ = [',
        indent(1, ',')(dirs.map(x => _dir(format(x), { id }, x))),
        ']',
      ]),

    dirs &&
      indent(0, '', [
        'for (const g of [f, d])',
        indent(1, '', [
          'for (const x of g) x.children = x.children ? x.children() : []',
        ]),
      ]),

    dirs ? 'const routes = [...f, ...d]' : 'const routes = files',
  ]);

const addIndex = (x, i) => (x.i = i);

var Routes = ({
  format = noop,
  keepEmpty,
  importDefault = false,
  importProp = 'import',
  resolve,
  sortFiles,
  sortDirs,
}) => {
  const routes = {};

  const add = file => {
    routes[file.path] = file;
  };

  const update = (file, previous) => {
    delete routes[previous.path];
    routes[file.path] = file;
  };

  const remove = ({ path }) => {
    if (!routes[path]) return
    delete routes[path];
  };

  const filter = keepEmpty ? identity : x => x.filter(notEmpty);

  const generate = (dirs = []) => {
    const files = filter(Object.values(routes));

    if (sortFiles) files.sort(sortFiles);
    if (sortDirs) dirs.sort(sortDirs);

    files.forEach(addIndex);
    if (dirs) dirs.forEach(addIndex);

    return _generate(
      { format, importDefault, importProp, resolve },
      files,
      dirs
    )
  };

  return {
    add,
    update,
    remove,

    generate,
  }
};

const _extras = extras => 'const extras = ' + JSON.stringify(extras, false, 2);

var Extras = options => {
  const extras = {};

  const getId = options.id ? file => file.id : file => file.path;

  const add = file => {
    extras[getId(file)] = file.extra;
  };

  const update = file => {
    if (_(extras[getId(file)]) === _(file.extra)) return false
    extras[getId(file)] = file.extra;
  };

  const remove = file => {
    delete extras[getId(file)];
  };

  const generate = () => _extras(extras);

  return {
    add,
    update,
    remove,

    generate,
  }
};

const now = Date.now;

const resolved = Promise.resolve();

const wait = delay => new Promise(resolve => setTimeout(resolve, delay));

const posixify = x => x.replace(/\\/g, '/');

var builder = (options = {}) => {
  const {
    dir,
    write: { routes: writeRoutes, tree: writeTree, extras: writeExtras } = {},
    merged = false,
    buildDebounce = 50,
    writeFile: _writeFile = (path, contents, encoding = 'utf8') =>
      fs.promises.writeFile(path, contents, encoding),
    log = console,
  } = options;

  const files = {};

  const parse = parseFile(options);
  let errors = [];

  const hasRoutes = writeRoutes || merged;
  const hasTree = writeTree || merged;
  const hasExtras = !!writeExtras;

  const api = {
    // add: file => builders.forEach(x => x.add(file)),
    add: (...args) => doAdd(...args),
    // update: (file, previous) => builders.forEach(x => x.update(file, previous)),
    update: (...args) => doUpdate(...args),
    // remove: file => builders.forEach(x => x.remove(file)),
    remove: (...args) => doRemove(...args),
  };

  const tree = hasTree && Tree(options, { parse, build: api });
  const routes = (hasRoutes || hasTree) && Routes(options);
  const extras = hasExtras && Extras(options);

  const builders = [routes, tree].filter(Boolean);

  let started = false;
  let timeout = null;
  let scheduled = false;
  let running = false;
  // NOTE start invalidated to ensure everything will be built on first run,
  // even if there are no target files
  const invalidated = { build: true, extras: true };
  const startDeferred = Deferred();
  let buildPromise = Promise.resolve();
  // a promise that resolves when we arrive to a point when we might be
  // idle (but not sure, because another volley of changes may have happened
  // since we started processing the one for which this promise was created)
  let idlePromise = Promise.resolve();
  let startTime = now();
  let latches = 0;
  let lastInvalidateTime = null;

  const isIdle = () =>
    errors.length > 0 ||
    (started && timeout === null && !scheduled && !running && latches === 0);

  const logBuildSuccess = args => {
    const targets = args.flat().filter(Boolean);
    if (!targets.length) {
      log.info('Nothing changed');
      return
    }
    const duration = now() - startTime;
    startTime = null;
    log.info(
      `Written: ${targets.map(() => '%s*')} (%sms)`,
      ...targets.map(target => path.resolve(target)),
      duration
    );
  };

  const writeFile = (...args) =>
    Promise.resolve(_writeFile(...args)).then(() => args[0]);

  const build = async () => {
    if (!routes && !tree) return

    running = true;

    const dirs = tree ? await tree.prepare() : null;

    const _routes = routes.generate(dirs);

    const _tree = hasTree && tree.generate();

    const promises = [];

    if (merged) {
      const contents = indent(0, '\n', [
        _routes,
        _tree,
        `export { f as files, d as dirs, routes, tree }\n`,
      ]);
      promises.push(writeFile(writeRoutes, contents));
    } else {
      if (writeRoutes) {
        const contents = indent(0, '\n', [
          _routes,
          `export { f as files,${dirs ? ` d as dirs,` : ''} routes }\n`,
        ]);
        promises.push(writeFile(writeRoutes, contents));
      }
      if (writeTree) {
        // const prefix = writeRoutes
        //   ? `import f from '${writeRoutes}'\n\nconst d = f.dirs`
        //   : _routes
        // const contents = prefix + '\n\n' + _tree
        const contents = indent(0, '\n', [
          writeRoutes
            ? `import { files as f, dirs as d } from '${writeRoutes}'`
            : _routes,
          _tree,
          'export default tree',
        ]);
        promises.push(writeFile(writeTree, contents));
      }
    }

    return Promise.all(promises)
  };

  const buildExtras = async () => {
    if (!extras) return

    const _extras = extras.generate();

    const contents = indent(0, '\n', [
      //
      _extras,
      'export default extras',
    ]);

    return writeFile(writeExtras, contents)
  };

  const schedule = () => {
    timeout = null;
    if (scheduled) return
    scheduled = true;
    buildPromise = buildPromise
      .then(() => {
        scheduled = false;
        const { build: rebuild, extras: rebuildExtras } = invalidated;
        invalidated.build = invalidated.extras = false;
        return Promise.all([rebuild && build(), rebuildExtras && buildExtras()])
      })
      .then(logBuildSuccess)
      .catch(err => {
        errors.push(err);
      })
      .finally(() => {
        running = false;
      });
    return buildPromise
  };

  let _resolveIdlePromise = noop;

  const invalidate = (debounce = buildDebounce) => {
    if (!started) return

    if (timeout !== null) {
      clearTimeout(timeout);
    }

    // NOTE we still need to resolve the previous idlePromise, or _onIdle will
    // hang on it (especially if we've just cancelled an active timeout just
    // above)
    const resolvePrevious = _resolveIdlePromise;

    idlePromise = new Promise(resolve => {
      _resolveIdlePromise = resolve;
      const doSchedule = () => {
        if (latches > 0) {
          resolve();
          return
        }
        schedule().finally(resolve);
      };
      timeout = setTimeout(doSchedule, debounce);
      notifyChange(); // must happen once timeout is non null (for idle state)
    });

    resolvePrevious();
  };

  const release = (canceled = false) => {
    latches--;
    if (canceled) {
      log.info('Bailing out');
      return
    }
    if (started && latches === 0) {
      invalidate(Math.max(0, buildDebounce - (Date.now() - lastInvalidateTime)));
    }
  };

  // invalidates (i.e. make busy/non idle, and wait to see if more changes are
  // coming for the debounce duration) right when the call is made, then wait
  // for at least the debounce delay (hene lastInvalidateTime), and wait even
  // longer if the given promise has not resolved at this point
  const invalidateUntil = promise => {
    lastInvalidateTime = Date.now();
    latches++;
    return promise.finally(release)
  };

  const input = () => {
    if (startTime === null) {
      startTime = now();
      latches = 0;
      errors = [];
    }
  };

  const pushError = err => {
    errors.push(err);
  };

  const start = () => {
    input();
    started = true;
    invalidate(0);
    startDeferred.resolve();
  };

  // NOTE parse is async, but we need add/update to be sync
  const _parse = async (pathStats, previous) => {
    const file = await parse(pathStats, previous);
    // canceled
    if (file === false) return false
    return file
  };

  const doAdd = file => {
    files[file.relative] = file;
    if (file === false) return false
    if (extras && extras.add(file) !== false) {
      invalidated.extras = true;
    }
    invalidated.build = true;
    builders.forEach(x => x.add(file));
  };

  const add = pathStats => {
    input();
    const [, stats] = pathStats;
    if (stats.isDirectory()) return
    invalidateUntil(
      _parse(pathStats)
        .then(doAdd)
        .catch(pushError)
    );
  };

  const doUpdate = (file, previous) => {
    files[file.relative] = file;

    if (file === false) return false

    if (
      extras &&
      file.rebuildExtras !== false &&
      extras.update(file, previous) !== false
    ) {
      invalidated.extras = true;
    }

    if (file.rebuild === false) return false

    invalidated.build = true;

    builders.forEach(x => x.update(file, previous));
  };

  const update = pathStats => {
    input();
    const [path, stats] = pathStats;
    if (stats.isDirectory()) return
    const previous = files[path];
    invalidateUntil(
      _parse(pathStats, previous)
        .then(file => doUpdate(file, previous))
        .catch(pushError)
    );
  };

  const doRemove = file => {
    delete files[file.relative];
    if (extras && extras.remove(file) !== false) invalidated.extras = true;
    invalidated.build = true;
    builders.forEach(x => x.remove(file));
    invalidate();
  };

  const remove = ([path, stats]) => {
    try {
      input();
      if (stats.isDirectory()) return
      const file = files[path];
      if (!file) return

      delete files[path];

      if (extras && extras.remove(file) !== false) {
        invalidated.extras = true;
      }

      invalidated.build = true;
      api.remove(file);

      invalidate();
    } catch (err) {
      pushError(err);
    }
  };

  const _onIdle = () =>
    isIdle() ? resolved : Promise.all([idlePromise, buildPromise]).then(_onIdle);

  const onIdle = async (changeTimeout = 0) => {
    await startDeferred.promise;

    if (changeTimeout) {
      // we stop waiting early if Routix has caught the change (waitChange)
      // -- this ensures optimal waiting time but, unfortunately, in the
      // marginal case of when user deletes/renames a Routix page file;
      // we're still degenerate (i.e. wait full delay) for any other source
      // watched by Rollup only...
      await Promise.race([wait(changeTimeout), onChange()]);
    }

    await _onIdle();

    if (errors.length > 0) {
      // throw errors[0]
      if (errors.length === 1) {
        throw errors[0]
      }
      const err = new Error(
        `Build errors (${errors.length})\n1. ${errors[0].stack}`
      );
      err.name = 'RoutixBuildError';
      err.errors = errors;
      errors = [];
      throw err
    }
  };

  let changeListeners = [];

  const notifyChange = () => {
    for (const f of changeListeners) f();
    changeListeners = [];
  };

  const onChange = () => new Promise(resolve => changeListeners.push(resolve));

  // NOTE for some reason, CheapWatch seems to give posix path on Windows
  const get = filename => files[posixify(path.relative(dir, filename))];

  return { start, add, update, remove, onChange, onIdle, get }
};

var findup = (from, target) => {
  let last = null;
  let cur = from;
  while (cur !== last) {
    const file = path.resolve(cur, target);
    if (fs__default.existsSync(file)) {
      return file
    }
    last = cur;
    cur = path.dirname(cur);
  }
  throw new Error(`Could not find ${target} from ${from} and upper`)
};

// we need to find up because we're probably in /dist
let _root;
const root = () =>
  _root || (_root = path.dirname(findup(__dirname, 'package.json')));
const defaultRoutesPath = () => path.resolve(root(), 'routes.js');
const defaultTreePath = () => path.resolve(root(), 'tree.js');

const parseExtensions = (extensions = []) => {
  if (!extensions) return extensions
  return extensions.map(ext => (!ext.startsWith('.') ? '.' + ext : ext))
};

const emptyObject = {};

/* eslint-disable no-console */
const wrapConsole = fn => (msg, ...args) =>
  fn(msg.replace(/%s\*/g, '%s', ...msg));
const defaultLogger = {
  log: wrapConsole(console.log).bind(console, '[routix]'),
  info: wrapConsole(console.info).bind(console, '[routix]'),
  error: wrapConsole(console.error).bind(console, '[routix]'),
};
/* eslint-enable no-console */

const parseOptions = ({
  /**
   * @type {string}
   */
  dir,

  /**
   * @type {string[]}
   */
  extensions = [],

  /**
   * @type {function}
   */
  ignore = path => /(?:^|\/)(?:node_modules|\.git)\//.test(path),

  /**
   * @type {bool | { routes: bool|string, tree: bool|string }}
   *
   *     write: true|false
   *
   *     write: { routes: true|false, tree: true|false }
   *
   *     write: { routes: '/path/to/file', tree: '' }
   */
  write,

  /**
   * @type {bool}
   *
   * Whether to write a single `routes.js` file, or merge routes and tree in the
   * same file.
   */
  merged = true,

  /**
   * @type {bool} Adds an `id` from a hash of absolute path.
   */
  id = true,

  /**
   * @type {bool}
   *
   * Whether to watch FS after initial build.
   *
   * NOTE When used in Rollup, this option is set automatically by the plugin,
   * based on the ROLLUP_WATCH env variable (it can be overridden, but it's
   * probably not what you want).
   */
  watch = null,

  /**
   * @type {int|falsy}
   *
   * Defer Rollup build by this duration (ms); this is needed to ensure that
   * our file watcher has the time to pick file changes (and then holds Rollup
   * until routes.js is generated).
   *
   * NOTE This is only useful when used as a bundler (Rollup) plugin.
   */
  watchDelay = 40,

  /**
   * @type {bool} Prepend paths with a leading slash
   */
  leadingSlash = false,

  /**
   * @type {bool} Import default import
   */
  importDefault = false,

  /**
   * @type {string} Name of the import property in route objects
   */
  importProp = 'import',

  /**
   * @type {function} Resolve an import path in routes.js
   */
  resolve = identity,

  /**
   * Files:
   *
   *     ({ isFile: true, absolute, relative, path, extension }) => item | undefined
   *
   * Directories:
   *
   *     ({ isFile: false, absolute, relative, path }) => item | undefined
   *
   * Virtual directories (when building tree from modified paths):
   *
   *     ({ isVirtual: true, path }) => item | undefined
   */
  parse = identity,

  /**
   * Alternative way to provide parse (allow to preprocess options).
   *
   * @type {options => (item, previous) => parsed}
   */
  parser,

  /**
   * @type {({ isFile: bool, path: string }) => object}
   *
   * item => props
   */
  format = () => emptyObject,

  /**
   * @type {bool} `true` to auto start Routix (only with node API)
   */
  start = false,

  // --- Advanced ---

  /**
   * @type {int} Number of ms to wait for a possible new event before starting
   * the build process.
   */
  buildDebounce = 50,

  /**
   * @type {object} Custom logger (with `console` API)
   */
  log = defaultLogger,

  /**
   * @type {function} Custom file writer: `async (name, contents) => {}`
   */
  writeFile,

  /**
   * @type {function} Custom sorter for files.
   */
  sortFiles = null,
  /**
   * @type {function} Custom sorter for dirs.
   */
  sortDirs = null,
  /**
   * @type {function} Custom sorter for tree children.
   */
  sortChildren = null,

  /**
   * @type {Function} Resolve conflicts between file node with same path.
   */
  resolveConflict,
} = {}) => {
  const options = {
    id,
    watchDelay,
    dir: dir && path.resolve(dir),
    extensions: parseExtensions(extensions),
    ignore,
    watch,
    leadingSlash,
    importDefault,
    importProp,
    resolve,
    parse,
    format,
    merged,
    write: {
      routes:
        !write ||
        write === true ||
        !write.hasOwnProperty('routes') ||
        write.routes === true
          ? defaultRoutesPath()
          : path.resolve(write.routes),
      tree:
        !merged &&
        (!write ||
        write === true ||
        !write.hasOwnProperty('tree') ||
        write.tree === true
          ? defaultTreePath()
          : path.resolve(write.tree)),
      extras: write && write.extras,
    },
    start,
    // internal (for testing)
    writeFile,
    buildDebounce,
    log,
    sortFiles,
    sortDirs,
    sortChildren,
    resolveConflict,
  };

  if (parser) {
    options.parse = parser(options);
  }

  return options
};

const IS_ROUTIX = Symbol('IS_ROUTIX');

const createRoutix = arg => {
  if (arg[IS_ROUTIX]) return arg

  const options = parseOptions(arg);

  const { log, write, start } = options;

  const build = builder(options);

  const read = reader(options, build);

  const writeTargets = Object.values(write).filter(Boolean);

  const isWriteTarget = id => writeTargets.some(x => x === id);

  const { onIdle, get } = build;
  const { init, isWatchedFile, close } = read;

  if (start) {
    setTimeout(() => {
      read.init().catch(err => log.error(err));
    });
  }

  return {
    [IS_ROUTIX]: true,
    options,
    start: init,
    onIdle,
    get,
    isWriteTarget,
    isWatchedFile,
    close,
  }
};

module.exports = createRoutix;
//# sourceMappingURL=routix.js.map
